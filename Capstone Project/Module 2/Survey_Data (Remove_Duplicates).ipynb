{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2ae341",
   "metadata": {},
   "source": [
    "# **REMOVING DUPLICATES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5096cdb",
   "metadata": {},
   "source": [
    "#### IMPORT REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0b32e",
   "metadata": {},
   "source": [
    "#### LOAD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0256f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the Dataset\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Dataset suceesfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6ade1",
   "metadata": {},
   "source": [
    "#### IDENTIFYING DUPLICATE ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e216f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FILTER ONLY DUPLICATED ---\n",
    "\n",
    "# Let's pick a column that has unique values like 'ResponseId'\n",
    "duplicated = df[df.duplicated(subset=['ResponseId'])]\n",
    "\n",
    "# Count number of duplicated rows\n",
    "print(f\"Number of duplicates found: {df.duplicated(subset=['ResponseId']).sum()} rows\")\n",
    "\n",
    "# Check first 5 rows\n",
    "duplicated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12afae94",
   "metadata": {},
   "source": [
    "#### REMOVING DUPLICATE ROWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['ResponseId'], inplace=True)\n",
    "\n",
    "print(f\"Duplicates removed. New Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd8653",
   "metadata": {},
   "source": [
    "#### HANDLING MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb644617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values for all columns\n",
    "missing_data = df.isna().sum()\n",
    "\n",
    "print(f\"Number of missing data:\\n{missing_data[missing_data > 0].to_string()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51653cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check most frequent value for 'Edlevel' column\n",
    "most_freqv = df['EdLevel'].mode()[0]\n",
    "print(f\"The most frequent education level: {most_freqv}\")\n",
    "\n",
    "# Fill missing value with the most frequent value\n",
    "df['EdLevel'] = df['EdLevel'].fillna(most_freqv)\n",
    "\n",
    "# Verify the fix\n",
    "# This should print 0\n",
    "print(f\"Missing value in 'EdLevel' after imputation: {df['EdLevel'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae44e7d",
   "metadata": {},
   "source": [
    "#### Normalizing Compensation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34453770",
   "metadata": {},
   "source": [
    "For compensation/salaries, we almost always use median(the middle number) instead of mean(average).\n",
    "* **Why?** salaries are usually \"skewed\". A few people making huge amount (like > $2.000.000), this will pull the **Average** up to high, making it inacurate for a *Typical* person. The **Median** is safer because it ignore the *outliers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57735ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing value in 'ConvertedCompYearly'\n",
    "miss_comp = df['ConvertedCompYearly'].isna().sum()\n",
    "print(f\"Number of missing compensation values: {miss_comp}\")\n",
    "\n",
    "# Find median for 'ConvertedCompYearly' column\n",
    "comp_median = df['ConvertedCompYearly'].median()\n",
    "print(f\"The median yearly compensation is ${comp_median}\")\n",
    "\n",
    "# Fill missing data using median value\n",
    "df['ConvertedCompYearly'] = df['ConvertedCompYearly'].fillna(comp_median)\n",
    "\n",
    "# Let's verify the fix\n",
    "print(f\"Missing values after imputation: {df['ConvertedCompYearly'].isna().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice_session",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
