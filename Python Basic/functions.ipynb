{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554708cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'USA', 'cases': 250000, 'deaths': 5000}, {'country': 'India', 'cases': 180000, 'deaths': 3500}, {'country': 'Brazil', 'cases': 0, 'deaths': 2800}]\n",
      "[2.0, 1.9444444444444444, 0]\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 250000, \"deaths\": 5000},\n",
    "    {\"country\": \"India\", \"cases\": 180000, \"deaths\": 3500},\n",
    "    {\"country\": \"Brazil\", \"cases\": None, \"deaths\": 2800}\n",
    "]\n",
    "\n",
    "# 1. Clean missing data\n",
    "def clean_missing(data, default=0):\n",
    "    return[\n",
    "        {k: v if v is not None else default\n",
    "         for k, v in entry.items()}\n",
    "        for entry in data\n",
    "    ]\n",
    "\n",
    "# 2. Calculate mortality rate\n",
    "def mortality_rate(entry):\n",
    "    return (entry[\"deaths\"] / entry[\"cases\"]) * 100 if entry[\"cases\"] > 0 else 0\n",
    "\n",
    "# 3. Apply analysis\n",
    "cleaned = clean_missing(covid_data)\n",
    "rates = list(map(mortality_rate, cleaned))\n",
    "\n",
    "print(cleaned)\n",
    "print(rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dabeeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "None\n",
      "72\n",
      "[85, 78]\n",
      "None\n",
      "['invalid_string']\n",
      "None\n",
      "üö® New York alerts: 2023-05-01 (Rain, 68¬∞F) | 2023-05-03 (Sunny, 85¬∞F)\n"
     ]
    }
   ],
   "source": [
    "# WEATHER DATA\n",
    "weather_data = [\n",
    "    {\"city\": \"New York\", \"date\": \"2023-05-01\", \"temp_f\": 68, \"condition\": \"Rain\"},\n",
    "    {\"city\": \"New York\", \"date\": \"2023-05-02\", \"temp_f\": 72, \"condition\": \"Cloudy\"},\n",
    "    {\"city\": \"New York\", \"date\": \"2023-05-03\", \"temp_f\": 85, \"condition\": \"Sunny\"},\n",
    "    {\"city\": \"Chicago\", \"date\": \"2023-05-01\", \"temp_f\": 62, \"condition\": \"Cloudy\"},\n",
    "    {\"city\": \"Chicago\", \"date\": \"2023-05-02\", \"temp_f\": None, \"condition\": \"Rain\"},  # Missing data\n",
    "    {\"city\": \"Chicago\", \"date\": \"2023-05-03\", \"temp_f\": 78, \"condition\": \"Sunny\"}\n",
    "]\n",
    "\n",
    "def f_to_c(temp_f):\n",
    "    \"\"\"\n",
    "    Convert Fahrenheit to Celsius.\n",
    "    Args:\n",
    "        temp_f (float/int): Temperature in Farenheit\n",
    "    Returns:\n",
    "        float: Temperature in Celcius, or None if input is None\n",
    "    \"\"\"\n",
    "    return (temp_f - 32) * 5/9 if temp_f is not None else None\n",
    "\n",
    "# Test cases\n",
    "print(f_to_c(68))  # Output: 20.0\n",
    "print(f_to_c(None)) # Output: None\n",
    "\n",
    "def clean_missing_temps(data, default=72): # Clean missing data\n",
    "    \"\"\"\n",
    "    Replace missing temperature values with a default.\n",
    "    Args:\n",
    "        data (list): List of weather day dictionaries\n",
    "        default (int/float): Fallback temperature value\n",
    "    Return:\n",
    "        list: Cleaned data with no None temps\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {**day, \"temp_f\": day[\"temp_f\"] if day[\"temp_f\"] is not None else default}\n",
    "        for day in data\n",
    "    ]\n",
    "# Test\n",
    "cleaned_data = clean_missing_temps(weather_data)\n",
    "print(cleaned_data[4][\"temp_f\"]) # Output: 72 (replaced None)\n",
    "#print(cleaned_data)\n",
    "\n",
    "def get_extremes(data, key, condition=lambda x: True):\n",
    "    \"\"\"\n",
    "    Find min/max values in data matching a condition.\n",
    "    Args:\n",
    "        data (list): List of dictionaries\n",
    "        key (str): Dictionary key to analyze\n",
    "        condition (function): Filter function\n",
    "    Return:\n",
    "        tuple: (main_value, max_value)\n",
    "    \"\"\"\n",
    "    values = [day[key] for day in data if condition(day) and day[key] is not None]\n",
    "    return (min(values), max(values)) if values else (None, None)\n",
    "# Test - Find hottest/coldest sunny days\n",
    "sunny_extremes = get_extremes(weather_data, \"temp_f\", condition=lambda day: day[\"condition\"] == \"Sunny\")\n",
    "print(sunny_extremes) #Output: (78, 85)\n",
    "\n",
    "def safe_analyze(func, data, fallback=(None, None)):\n",
    "    \"\"\"\n",
    "    Safely run analysis with error handling.\n",
    "    Args:\n",
    "        func (function): Analysis function\n",
    "        data (list): Input data\n",
    "        fallback: Value to return on failure\n",
    "    Returns:\n",
    "        func result or fallback\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return func(data)\n",
    "    except (ValueError, TypeError, KeyError) as e:\n",
    "        print(f\"‚ö†Ô∏è Analysis failed: {type(e).__name__} - {str(e)}\")\n",
    "        return fallback\n",
    "\n",
    "# Test with bad data\n",
    "bad_data = [{\"temp_f\": \"invalid_string\"}]\n",
    "result = safe_analyze(\n",
    "    lambda d: get_extremes(d, \"temp_f\"),\n",
    "    bad_data\n",
    ")\n",
    "print(result) # Output: ‚ö†Ô∏è Analysis failed: TypeError....-> (None, None)\n",
    "\n",
    "def weather_alert(data, city, temp_threshold=80, condition=\"Rain\"):\n",
    "    \"\"\"\n",
    "    Generate alerts for extreme weather conditions.\n",
    "    Args:\n",
    "        data (list): Weather data\n",
    "        city (str): Target city\n",
    "        temp_threshold (int): Heat alert threshold\n",
    "        condition (str): Dangerous weather condition\n",
    "    Returns:\n",
    "        str: Alert message\n",
    "    \"\"\"\n",
    "    alerts = [\n",
    "        f\"{day['date']} ({day['condition']}, {day['temp_f']}¬∞F)\"\n",
    "        for day in data\n",
    "        if day[\"city\"] == city\n",
    "        and (\n",
    "            (day[\"temp_f\"] is not None and day[\"temp_f\"] > temp_threshold)\n",
    "            or day[\"condition\"] == condition\n",
    "        )\n",
    "    ]\n",
    "    return (\n",
    "        f\"üö® {city} alerts: \" + \" | \".join(alerts) \n",
    "        if alerts \n",
    "        else f\"‚úÖ No alerts for {city}\"\n",
    "    )\n",
    "\n",
    "# Test\n",
    "print(weather_alert(weather_data, \"New York\"))\n",
    "# Output: \"üö® New York alerts: 2023-05-03 (Sunny, 85¬∞F) | 2023-05-01 (Rain, 68¬∞F)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7840b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1: Movie Ratings\n",
    "\n",
    "def summarize_movies(titles, ratings=(0,), favorite=None):\n",
    "    return {\n",
    "        title: f\"{i}. {title.title()} rated {rating}\" + (\" ‚≠êÔ∏è\" if favorite and title.lower() == favorite.lower() else \"\")\n",
    "        for i, (title, rating) in enumerate(zip(titles, ratings), start=1)\n",
    "    }\n",
    "\n",
    "# Challenge 2: Animal Ages\n",
    "def describe_pets(names, ages=(0,), favorite=None):\n",
    "    return {\n",
    "        name: f\"{i}. {name.title()} is {age} years old\" +\n",
    "            (\" ‚ù§Ô∏è\" if favorite and name.lower() == favorite.lower() else \"\")\n",
    "        for i, (name, age) in enumerate(zip(names, ages), start=1)\n",
    "    }\n",
    "    \n",
    "# Challenge 3: Book Ratings\n",
    "def book_reviews(books, ratings=(0,), highlight=4.0):\n",
    "    return {\n",
    "        book: f\"{i}. {book.title()} rated {rating}\" +\n",
    "        (\" ‚≠êÔ∏è\" if rating >= highlight else \"\")\n",
    "        for i, (book, rating) in enumerate(zip(books, ratings), start=1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c38d79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alice': '1. Alice scored 85', 'bob': '2. Bob scored 92 ‚≠êÔ∏è üèÜ', 'carol': '3. Carol scored 90 ‚≠êÔ∏è'}\n"
     ]
    }
   ],
   "source": [
    "def summarize_scores(names, scores=(0,), highlight=90):\n",
    "    top = max(scores)\n",
    "    return {\n",
    "        name: f\"{i}. {name.title()} scored {score}\" +\n",
    "        (\" ‚≠êÔ∏è\" if score >= highlight else \"\") +\n",
    "        (\" üèÜ\" if score == top else \"\")\n",
    "        for i, (name, score) in enumerate(zip(names, scores),  start=1)\n",
    "    }\n",
    "    \n",
    "students = [\"alice\", \"bob\", \"carol\"]\n",
    "scores = [85, 92, 90]\n",
    "\n",
    "result = summarize_scores(students, scores)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aed5bfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alice': '1. Alice - Math: 95 ‚≠êÔ∏è, Science: 87, History: 90 ‚≠êÔ∏è', 'bob': '2. Bob - Math: 88, Science: 92 ‚≠êÔ∏è, History: 85', 'carol': '3. Carol - Math: 100 ‚≠êÔ∏è, Science: 98 ‚≠êÔ∏è, History: 99 ‚≠êÔ∏è'}\n"
     ]
    }
   ],
   "source": [
    "def summarize_multi_scores(names, subjects, scores_matrix, highlight=90):\n",
    "    averages = [sum(scores)/ len(scores) for scores in scores_matrix]\n",
    "    top_avg = max(averages)\n",
    "    \n",
    "    result = {}\n",
    "    for i, (name, scores, avg) in enumerate(zip(names, scores_matrix, averages), start=1):\n",
    "        subject_scores = [\n",
    "            f\"{subject.title()}: {score}{\" ‚≠êÔ∏è\" if score >= highlight else \"\"}\"\n",
    "            for subject, score in zip(subjects,scores)\n",
    "        ]\n",
    "        description = f\"{i}. {name.title()} - \" + \", \".join(subject_scores)\n",
    "        (\" üèÜ\" if avg == top_avg else \"\")\n",
    "        result[name] = description\n",
    "    return result\n",
    "\n",
    "students = [\"alice\", \"bob\", \"carol\"]\n",
    "subjects = [\"math\", \"science\", \"history\"]\n",
    "scores = [\n",
    "  [95, 87, 90],   # alice\n",
    "  [88, 92, 85],   # bob\n",
    "  [100, 98, 99]   # carol\n",
    "]\n",
    "\n",
    "result = summarize_multi_scores(students, subjects, scores)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alice': '1. Alice - Math: 95‚≠êÔ∏è, Science: 87, History: 90‚≠êÔ∏è', 'bob': '2. Bob - Math: 88, Science: 92‚≠êÔ∏è, History: 85', 'carol': '3. Carol - Math: 100‚≠êÔ∏è, Science: 98‚≠êÔ∏è, History: 99‚≠êÔ∏è üèÜ'}\n"
     ]
    }
   ],
   "source": [
    "def summarize_multi_scores(names, subjects, scores_matrix, highlight=90):\n",
    "    # First, calculate all student averages\n",
    "    averages = [sum(scores) / len(scores) for scores in scores_matrix]\n",
    "    top_avg = max(averages) \n",
    "    # Now build the dictionary\n",
    "    result = {\n",
    "        name: f\"{i}. {name.title()} - \" + \", \".join([\n",
    "            f\"{subject.title()}: {score}{'‚≠êÔ∏è' if score >= highlight else ''}\"\n",
    "            for subject, score in zip(subjects, scores)\n",
    "        ])\n",
    "        \n",
    "        for i, (name, scores, avg) in enumerate(zip(names, scores_matrix, averages), start=1)\n",
    "        \n",
    "    }\n",
    "    return result\n",
    "\n",
    "students = [\"alice\", \"bob\", \"carol\"]\n",
    "subjects = [\"math\", \"science\", \"history\"]\n",
    "scores = [\n",
    "  [95, 87, 90],   # alice\n",
    "  [88, 92, 85],   # bob\n",
    "  [100, 98, 99]   # carol\n",
    "]\n",
    "\n",
    "result = summarize_multi_scores(students, subjects, scores)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "15b53a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alice': '1. Alice -Math: 95 ‚≠êÔ∏è, Science: 87, History: 90 ‚≠êÔ∏è (avg: 90.67)', 'bob': '2. Bob -Math: 88, Science: 92 ‚≠êÔ∏è, History: 85 (avg: 88.33)', 'carol': '3. Carol -Math: 100 ‚≠êÔ∏è, Science: 98 ‚≠êÔ∏è, History: 99 ‚≠êÔ∏è (avg: 99.0) üèÜ'}\n"
     ]
    }
   ],
   "source": [
    "# Student Progress Report\n",
    "def report_card(names, subjects, scores_matrix, highlight=90, topper=None):\n",
    "     return {\n",
    "         name: f\"{i}. {name.title()} -\" + \", \".join([\n",
    "             f\"{subject.title()}: {score}{\" ‚≠êÔ∏è\" if  score >= highlight else \"\"}\"\n",
    "             for subject, score in zip(subjects, scores)\n",
    "             ]) + f\" (avg: {round(sum(scores)/len(scores), 2)})\" +\n",
    "         (\" üèÜ\" if topper and name.lower() == topper.lower() else \"\")\n",
    "         for i, (name, scores) in enumerate(zip(names, scores_matrix), start=1)\n",
    "     }\n",
    "\n",
    "names = [\"alice\", \"bob\", \"carol\"]\n",
    "subjects = [\"math\", \"science\", \"history\"]\n",
    "scores = [\n",
    "    [95, 87, 90],\n",
    "    [88, 92, 85],\n",
    "    [100, 98, 99]\n",
    "]\n",
    "\n",
    "output = report_card(names, subjects, scores, topper=\"carol\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b056c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'carol': '1. Carol is learning French - 1005 words learned (100.5%) üéâ üèÜ', 'bob': '2. Bob is learning Japanese - 920 words learned (92.0%) üå±', 'alice': '3. Alice is learning Spanish - 850 words learned (85.0%) üå±'}\n"
     ]
    }
   ],
   "source": [
    "# Language Learning Tracker\n",
    "def vocab_leaderboard(learners, languages, word_counts, goal=1000):\n",
    "    # sort and zip data by word_counts descending\n",
    "    sorted_data = sorted(zip(learners, languages, word_counts), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # get top scorer\n",
    "    top_score = sorted_data[0][2]\n",
    "    \n",
    "    # create ranked leaderboard\n",
    "    return {\n",
    "        learner: f\"{rank}. {learner.title()} is learning {language.title()} - {word_count} words learned ({round(word_count/goal * 100, 2)}%)\" +\n",
    "        (\" üéâ\" if word_count >= goal else \" üå±\") +\n",
    "        (\" üèÜ\" if word_count == top_score else \"\")\n",
    "        for rank, (learner, language, word_count) in enumerate(sorted_data, start=1)\n",
    "    }\n",
    "    \n",
    "# data\n",
    "learners = [\"alice\", \"bob\", \"carol\"]\n",
    "languages = [\"spanish\", \"japanese\", \"french\"]\n",
    "word_counts = [850, 920, 1005]\n",
    "\n",
    "#result\n",
    "result = vocab_leaderboard(learners, languages, word_counts)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4a0faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'carol': '1. Carol from west - Total: $15000 (115.38%) ‚úÖ üèÜ', 'bob': '2. Bob from south - Total: $12000 (92.31%) ‚ö†Ô∏è', 'alice': '3. Alice from north - Total: $9800 (75.38%) ‚ö†Ô∏è'}\n"
     ]
    }
   ],
   "source": [
    "def sales_summary(sellers, regions, monthly_sales, target=13000):\n",
    "    # sorted data by monthly_sales descending\n",
    "    sorted_data = sorted(zip(sellers, regions, monthly_sales), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # top seller\n",
    "    top_seller = sorted_data[0][2]\n",
    "    \n",
    "    return {\n",
    "        seller: f\"{i}. {seller.title()} from {region} - Total: ${sales} ({round(sales/ target * 100, 2)}%)\" +\n",
    "        (\" ‚úÖ\" if sales >= target else \" ‚ö†Ô∏è\") +\n",
    "        (\" üèÜ\" if sales == top_seller else \"\")\n",
    "        for i, (seller, region, sales) in enumerate(sorted_data, start=1)\n",
    "    }\n",
    "\n",
    "sellers = [\"alice\", \"bob\", \"carol\"]\n",
    "regions = [\"north\", \"south\", \"west\"]\n",
    "monthly_sales = [9800, 12000, 15000]\n",
    "\n",
    "output = sales_summary(sellers, regions, monthly_sales)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50428153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'carol': ' 1. Carol from West - $15000 (115.38%) ‚úÖ üí° üèÜ', 'bob': ' 2. Bob from South - $12000 (92.31%)', 'alice': ' 3. Alice from North - $9800 (75.38%)'}\n"
     ]
    }
   ],
   "source": [
    "# SALES REPORT\n",
    "def advanced_sales_report(sellers, regions, monthly_sales, target=13000):\n",
    "    # sorted data by monthly_sales descending\n",
    "    sorted_data = sorted(zip(sellers, regions, monthly_sales), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # top seller\n",
    "    top_seller = sorted_data[0][2]\n",
    "    \n",
    "    # averages sales\n",
    "    averages = round(sum(monthly_sales)/ len(monthly_sales), 2)\n",
    "    \n",
    "    # Sales report\n",
    "    return {\n",
    "        seller: f\" {rank}. {seller.title()} from {region.title()} - ${sales} ({round(sales/target * 100, 2)}%\n",
    "        )\" +\n",
    "        (\" ‚úÖ\" if sales >= target else \"\") +\n",
    "        (\" üí°\" if sales > averages else \"\") +\n",
    "        (\" üèÜ\" if sales == top_seller else \"\")\n",
    "        for rank, (seller, region, sales) in enumerate(sorted_data, start=1)\n",
    "    }\n",
    "\n",
    "# data\n",
    "sellers = [\"alice\", \"bob\", \"carol\"]\n",
    "regions = [\"north\", \"south\", \"west\"]\n",
    "monthly_sales = [9800, 12000, 15000]\n",
    "\n",
    "# output\n",
    "output = advanced_sales_report(sellers, regions, monthly_sales)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e83b8aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'USA', 'cases': 250000, 'deaths': 5000, 'recovered': 0}, {'country': 'India', 'cases': 180000, 'deaths': 3500, 'recovered': 120000}, {'country': 'Brazil', 'cases': 0, 'deaths': 2800, 'recovered': 80000}]\n"
     ]
    }
   ],
   "source": [
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 250000, \"deaths\": 5000, \"recovered\": None},\n",
    "    {\"country\": \"India\", \"cases\": 180000, \"deaths\": 3500, \"recovered\": 120000},\n",
    "    {\"country\": \"Brazil\", \"cases\": None, \"deaths\": 2800, \"recovered\": 80000}\n",
    "]\n",
    "\n",
    "# Cleaning Values\n",
    "def clean_missing(data, default=0):\n",
    "    cleaned = []\n",
    "    for country in covid_data:\n",
    "        new_country = {}\n",
    "        for key, value in country.items():\n",
    "            new_country[key] = value if value is not None else default\n",
    "        cleaned.append(new_country)\n",
    "    return cleaned\n",
    "        \n",
    "cleaned_data = clean_missing(covid_data)\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'Test', 'cases': 0, 'deaths': 50, 'recovered': 0}]\n",
      "[{'country': 'USA', 'cases': 250000, 'deaths': 5000, 'recovered': 0}, {'country': 'India', 'cases': 180000, 'deaths': 3500, 'recovered': 120000}, {'country': 'Brazil', 'cases': 0, 'deaths': 2800, 'recovered': 80000}]\n",
      "2.0\n",
      "None\n",
      "[{'country': 'USA', 'mortality': 2.0}, {'country': 'India', 'mortality': 1.94}, {'country': 'Brazil', 'mortality': None}]\n"
     ]
    }
   ],
   "source": [
    "# COVID19 DATA\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 250000, \"deaths\": 5000, \"recovered\": None},\n",
    "    {\"country\": \"India\", \"cases\": 180000, \"deaths\": 3500, \"recovered\": 120000},\n",
    "    {\"country\": \"Brazil\", \"cases\": None, \"deaths\": 2800, \"recovered\": 80000}\n",
    "]\n",
    "# clean data\n",
    "def clean_missing(data, default=0, allow_negative=False):\n",
    "    \"\"\"\n",
    "    cleaning None value to 0.\n",
    "    Args:\n",
    "        data (list): List contain a dictionaries of covid_data\n",
    "        default: Value to use for missing data\n",
    "    Return:\n",
    "        list: Cleaned data\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            key: default if (\n",
    "                value is None or \n",
    "                (not allow_negative and isinstance(value, (int, float))) and value < 0\n",
    "            )\n",
    "            else value for key, value in country.items()\n",
    "        }\n",
    "        for country in data\n",
    "    ]\n",
    "# Test with negative data\n",
    "test_data = [\n",
    "    {\"country\": \"Test\", \"cases\": -100, \"deaths\": 50, \"recovered\": None}\n",
    "]\n",
    "print(clean_missing(test_data))\n",
    "# Output: [{'country': 'Test', 'cases': 0, 'deaths': 50, 'recovered': 0}]\n",
    "    \n",
    "# Mortality rate\n",
    "def calculate_mortality(country_data):\n",
    "    try:\n",
    "        rate = (country_data[\"deaths\"] / country_data[\"cases\"] * 100)\n",
    "        return round(rate, 2) if rate >= 0 else None\n",
    "    except (TypeError, ZeroDivisionError):\n",
    "        return None\n",
    "\n",
    "# Filtering by mortality rate\n",
    "def filter_mortality(data, threshold=1.5):\n",
    "    filtered = []\n",
    "    for country in data:\n",
    "        if calculate_mortality(country) is not None\n",
    "        and calculate_mortality(country) > threshold:\n",
    "            filtered.append(country)\n",
    "    return filtered\n",
    "\n",
    "# Pipeline\n",
    "def analyze_covid(data):\n",
    "    cleaned = clean_missing(data)\n",
    "    result = []\n",
    "    for country in cleaned:\n",
    "        result.append(\n",
    "            {\"country\": country[\"country\"], \"mortality\": calculate_mortality(country)}\n",
    "        )\n",
    "    return result\n",
    "\n",
    "# Testing cleaned data\n",
    "cleaned_data = clean_missing(covid_data)\n",
    "print(cleaned_data)\n",
    "\n",
    "# Testing mortality\n",
    "print(calculate_mortality(cleaned_data[0]))  # 2.0 (5000/250000*100)\n",
    "print(calculate_mortality({\"cases\": 0, \"deaths\": 100}))  # None\n",
    "\n",
    "# Testing analyze_covid\n",
    "print(analyze_covid(covid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2563bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data: [{'product': 'Laptop', 'price': 999.99, 'units_sold': 120, 'return_rate': 0.02}, {'product': 'Mouse', 'price': 24.99, 'units_sold': 350, 'return_rate': 0}, {'product': 'Keyboard', 'price': 49.99, 'units_sold': 200, 'return_rate': 0.05}, {'product': 'Monitor', 'price': 199.99, 'units_sold': 0, 'return_rate': 0.01}]\n",
      "Revenues: [None]\n",
      "Top Sellers: ['Mouse', 'Keyboard']\n"
     ]
    }
   ],
   "source": [
    "# RETAIL SALES\n",
    "sales_data = [\n",
    "    {\"product\": \"Laptop\", \"price\": 999.99, \"units_sold\": 120, \"return_rate\": 0.02},\n",
    "    {\"product\": \"Mouse\", \"price\": 24.99, \"units_sold\": 350, \"return_rate\": None},\n",
    "    {\"product\": \"Keyboard\", \"price\": 49.99, \"units_sold\": 200, \"return_rate\": 0.05},\n",
    "    {\"product\": \"Monitor\", \"price\": 199.99, \"units_sold\": None, \"return_rate\": 0.01}\n",
    "]\n",
    "\n",
    "# Cleaning data\n",
    "def clean_sales_data(data, default_units=0, default_return=0):\n",
    "    \"\"\"\n",
    "    Replace None values in sales data with defaults.\n",
    "    Args:\n",
    "        data: List of sales dictionaries\n",
    "        default_units: Value for missing units_sold\n",
    "        default_return: value for missing return_rate\n",
    "    Return:\n",
    "        list: Cleaned data\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for new_data in data:\n",
    "        sales = {}\n",
    "        for key, value in new_data.items():\n",
    "            if key == \"units_sold\" and value is None:\n",
    "                sales[key] = default_units\n",
    "            elif key == \"return_rate\" and value is None:\n",
    "                sales[key] = default_return\n",
    "            else:\n",
    "                sales[key] = value\n",
    "        cleaned.append(sales)\n",
    "    return cleaned\n",
    "\n",
    "# Calculate Revenue\n",
    "def calculate_revenue(product):\n",
    "    \"\"\"\n",
    "    Calculate net revenue (adjusted for returns).\n",
    "    Formula: (Price * units_sold) * (1 - return_rate)\n",
    "    Args:\n",
    "        product: Single product dictionary \n",
    "    Return:\n",
    "        float: Net revenue or None if invalid data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if product[\"units_sold\"] < 0 or product[\"return_rate\"] < 0:\n",
    "            raise ValueError(\"Negative values are not allowed\")\n",
    "        revenue = (product[\"price\"] * product[\"units_sold\"]) * (1 - product[\"return_rate\"])\n",
    "        return round(revenue, 2)\n",
    "    except (TypeError):\n",
    "        return None\n",
    "\n",
    "# Find Top performer\n",
    "def get_top_products(data, metric=\"revenue\", n=3):\n",
    "    \"\"\"\n",
    "    Get top N products by specified metric.\n",
    "    Args:\n",
    "        data: List of cleaned product dictionaries\n",
    "        metric: \"revenue\" or \"units_sold\"\n",
    "        n: Number of top products to return\n",
    "    Return:\n",
    "        list: Sorted product names\n",
    "    \"\"\"\n",
    "    valid_data = [p for p in data if p.get(metric) is not None]\n",
    "    if not valid_data:\n",
    "        print(f\"Warning: No valid data for metric '{metric}'\")\n",
    "        return []\n",
    "    return [p[\"product\"] for p in sorted(valid_data, key=lambda x: x[metric], reverse=True) [:n]]\n",
    "    \n",
    "cleaned_data = clean_sales_data(sales_data)\n",
    "revenues = [calculate_revenue(cleaned_data)]\n",
    "top_sellers = get_top_products(cleaned_data, \"units_sold\", 2)\n",
    "\n",
    "print(\"Cleaned Data:\", cleaned_data)\n",
    "print(\"Revenues:\", revenues)\n",
    "print(\"Top Sellers:\", top_sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b00a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data: [{'id': 101, 'name': 'Wireless Earbuds', 'category': 'Electronics', 'stock': 45, 'cost': 25.99, 'price': 59.99, 'margin': 34.0, 'neeed_restock': False}, {'id': 102, 'name': 'Yoga Mat', 'category': 'Fitness', 'stock': 120, 'cost': 12.5, 'price': 29.99, 'margin': 17.5, 'neeed_restock': False}, {'id': 103, 'name': 'Blender', 'category': 'Home', 'stock': 0, 'cost': 40.0, 'price': 89.99, 'margin': 50.0, 'neeed_restock': False}, {'id': 104, 'name': 'Notebook', 'category': 'Office', 'stock': 75, 'cost': 0.0, 'price': 4.99, 'margin': None, 'neeed_restock': False}, {'id': 105, 'name': 'Resistance Bands', 'category': 'Fitness', 'stock': 60, 'cost': 8.2, 'price': 24.99, 'margin': 16.8, 'neeed_restock': False}]\n",
      "Restock List: ['Blender']\n"
     ]
    }
   ],
   "source": [
    "# INVENTORY ANALYSIS\n",
    "inventory = [\n",
    "    {\"id\": 101, \"name\": \"Wireless Earbuds\", \"category\": \"Electronics\", \"stock\": 45, \"cost\": 25.99, \"price\": 59.99},\n",
    "    {\"id\": 102, \"name\": \"Yoga Mat\", \"category\": \"Fitness\", \"stock\": 120, \"cost\": 12.50, \"price\": 29.99},\n",
    "    {\"id\": 103, \"name\": \"Blender\", \"category\": \"Home\", \"stock\": 0, \"cost\": 40.00, \"price\": 89.99},\n",
    "    {\"id\": 104, \"name\": \"Notebook\", \"category\": \"Office\", \"stock\": 75, \"cost\": None, \"price\": 4.99},\n",
    "    {\"id\": 105, \"name\": \"Resistance Bands\", \"category\": \"Fitness\", \"stock\": 60, \"cost\": 8.20, \"price\": 24.99}\n",
    "]\n",
    "\n",
    "# Cleaning data\n",
    "def clean_inventory(data, default_cost=0.0):\n",
    "    \"\"\"\n",
    "    Replace None cost with default, add margins, and flag out-of-stock items.\n",
    "    Args:\n",
    "        data:  List of inventory dictionaries\n",
    "        default_cost (float): default parameter 0.0\n",
    "    Return:\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for new_inventory in data:\n",
    "        new_data = {}\n",
    "        for key, value in new_inventory.items():\n",
    "            if key == \"cost\" and value is None:\n",
    "                new_data[key] = default_cost\n",
    "            else:\n",
    "                new_data[key] = value\n",
    "        new_data[\"margin\"] = (round(new_inventory[\"price\"] - new_inventory[\"cost\"], 1) if new_inventory[\"cost\"] is not None else None)\n",
    "        new_data[\"need_restock\"] = True if key == \"cost\" and value is None else False\n",
    "        cleaned.append(new_data)\n",
    "    return cleaned\n",
    "\n",
    "# Financial Analysis\n",
    "\n",
    "\n",
    "# Smart Restocker\n",
    "def generate_restock_list(data, threshold=10):\n",
    "    \"\"\"\n",
    "    Identify items needing restock (stock <= threshold).\n",
    "    AND with margin > 20%.\n",
    "    Returns:\n",
    "        list: Sorted by most needed (lowest stock first)\n",
    "    \"\"\"\n",
    "    return sorted(\n",
    "        [item for item in data if item[\"stock\"] <= threshold and (item.get(\"margin\") or 0) > 20], \n",
    "        key=lambda x: x[\"stock\"]\n",
    "    )\n",
    "\n",
    "def sell_product(inventory, product_id, quantity):\n",
    "    updated_inventory = []\n",
    "    sale_success = False\n",
    "    \n",
    "    for product in inventory:\n",
    "        # make a copy to avoid modifying original data\n",
    "        product_copy = product.copy()\n",
    "        \n",
    "        #find matching product\n",
    "        if product[\"id\"] == product_id:\n",
    "            # validate quantity\n",
    "            if quantity <= 0:\n",
    "                print(f\"üõë invalid quantity ({quantity} for  {product['name']})\")\n",
    "                updated_inventory.append(product_copy)\n",
    "                return, False, inventory # Early return on invalid input\n",
    "            \n",
    "            # checking stock and apply discounts\n",
    "            if product[\"stock\"] >= quantity and quantity > 0:\n",
    "                # Bulk discount\n",
    "                if quantity > 50:\n",
    "                    product_copy[\"price\"] *= 0.9 # 10% discount\n",
    "                    print(f\"üéâ Applied 10% bulk discount to {product['name']}\")\n",
    "                    \n",
    "                # process transaction\n",
    "                product_copy[\"stock\"] -= quantity\n",
    "                sale_success = True\n",
    "                print(f\"‚úÖ Sold {quantity} units of {product['name']}\")\n",
    "                product_copy[\"last_sale\"] = datetime.now().isoformat() # add timestamp\n",
    "                \n",
    "                # restock alert\n",
    "                if product_copy[\"stock\"] < 10:\n",
    "                    product_copy[\"need_restock\"] = True\n",
    "                    print(f\"‚ö†Ô∏è Low stock alert for {product['name']}\")\n",
    "                else:\n",
    "                    print(f\"üõë Not enough stock for {quantity} units of {product[\"name\"]}\")\n",
    "        updated_inventory.append(product_copy)\n",
    "    return sale_success, updated_inventory\n",
    "\n",
    "cleaned_data = clean_inventory(inventory)\n",
    "#metrics = analyze_profitability(cleaned_data)\n",
    "restock_list = generate_restock_list(cleaned_data)\n",
    "\n",
    "print(\"Cleaned Data:\", cleaned_data)  # First item sample\n",
    "#print(\"Metrics:\", metrics)\n",
    "print(\"Restock List:\", [item[\"name\"] for item in restock_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "27c68556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'Winter Jacket', 'units': 420, 'return_rate': 0.08}\n",
      "{'product': 'Heating Blanket', 'units': 380, 'return_rate': 0.12}\n",
      "{'product': 'Chocolate Box', 'units': 510, 'return_rate': 0.03}\n",
      "{'product': 'Teddy Bear', 'units': 290, 'return_rate': 0.05}\n",
      "{'product': 'Yoga Mat', 'units': 320, 'return_rate': 0.04}\n",
      "{'product': 'Dumbbells', 'units': 180, 'return_rate': 0.15}\n"
     ]
    }
   ],
   "source": [
    "# SALES DATA\n",
    "sales_data = [\n",
    "    {\n",
    "        \"month\": \"Jan-2023\",\n",
    "        \"revenue\": 150000,\n",
    "        \"expenses\": 95000,\n",
    "        \"campaigns\": [\"New Year Sale\", \"Winter Clearance\"],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Winter Jacket\", \"units\": 420, \"return_rate\": 0.08},\n",
    "            {\"product\": \"Heating Blanket\", \"units\": 380, \"return_rate\": 0.12}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"month\": \"Feb-2023\",\n",
    "        \"revenue\": 185000,\n",
    "        \"expenses\": 110000,\n",
    "        \"campaigns\": [\"Valentine's Special\"],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Chocolate Box\", \"units\": 510, \"return_rate\": 0.03},\n",
    "            {\"product\": \"Teddy Bear\", \"units\": 290, \"return_rate\": 0.05}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"month\": \"Mar-2023\",\n",
    "        \"revenue\": None,\n",
    "        \"expenses\": 105000,\n",
    "        \"campaigns\": [],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Yoga Mat\", \"units\": 320, \"return_rate\": 0.04},\n",
    "            {\"product\": \"Dumbbells\", \"units\": 180, \"return_rate\": 0.15}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for campaigns in sales_data:\n",
    "    for top_product in campaigns[\"top_products\"]:\n",
    "        print(top_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "83186947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data Sample: {'month': 'Jan-2023', 'revenue': 150000, 'expenses': 95000, 'campaigns': ['New Year Sale', 'Winter Clearance'], 'top_products': [{'product': 'Winter Jacket', 'units': 420, 'return_rate': 0.08}, {'product': 'Heating Blanket', 'units': 380, 'return_rate': 0.12}], 'profit': 55000, 'has_campaigns': True}\n",
      "\n",
      "Campaign Analysis: {'avg_revenue_per_campaign': 167500.0, 'best_month': 'Feb-2023', 'campaign_coverage': 0.67}\n",
      "\n",
      "High Return Products: [{'product_name': 'Dumbbells', 'month': 'Mar-2023', 'return_rate': 0.15, 'units': 180}, {'product_name': 'Heating Blanket', 'month': 'Jan-2023', 'return_rate': 0.12, 'units': 380}, {'product_name': 'Winter Jacket', 'month': 'Jan-2023', 'return_rate': 0.08, 'units': 420}]\n",
      "\n",
      "Performance Report:\n",
      "\n",
      "    # Sales Performance Report\n",
      "    ## Financial Summary\n",
      "    - Total Profit: $25,000.00\n",
      "    - Most Profitable Month: Feb-2023 ($75,000.00)\n",
      "    - Average Revenue per Campaign: $167,500.00\n",
      "\n",
      "    ## Product Analysis\n",
      "    - Highest Return Product: Dumbbells\n",
      "    (15.0% in Mar-2023)\n",
      "    - Campaign Coverage: 67.0% of months\n",
      "    \n",
      "\n",
      "Next Month Prediction: {'predicted_revenue': 111667, 'predicted_profit': 8333, 'warning': None}\n"
     ]
    }
   ],
   "source": [
    "# SALES DATA\n",
    "sales_data = [\n",
    "    {\n",
    "        \"month\": \"Jan-2023\",\n",
    "        \"revenue\": 150000,\n",
    "        \"expenses\": 95000,\n",
    "        \"campaigns\": [\"New Year Sale\", \"Winter Clearance\"],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Winter Jacket\", \"units\": 420, \"return_rate\": 0.08},\n",
    "            {\"product\": \"Heating Blanket\", \"units\": 380, \"return_rate\": 0.12}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"month\": \"Feb-2023\",\n",
    "        \"revenue\": 185000,\n",
    "        \"expenses\": 110000,\n",
    "        \"campaigns\": [\"Valentine's Special\"],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Chocolate Box\", \"units\": 510, \"return_rate\": 0.03},\n",
    "            {\"product\": \"Teddy Bear\", \"units\": 290, \"return_rate\": 0.05}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"month\": \"Mar-2023\",\n",
    "        \"revenue\": None,\n",
    "        \"expenses\": 105000,\n",
    "        \"campaigns\": [],\n",
    "        \"top_products\": [\n",
    "            {\"product\": \"Yoga Mat\", \"units\": 320, \"return_rate\": 0.04},\n",
    "            {\"product\": \"Dumbbells\", \"units\": 180, \"return_rate\": 0.15}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Clean data\n",
    "def clean_sales_data(data, default_revenue=0):\n",
    "    \"\"\"\n",
    "    Clean missing data and calculate drived metrics:\n",
    "    - Add \"profit\" (revenue - expenses)\n",
    "    - Flag months with no campaigns\n",
    "    - Replace missing revenue with default\n",
    "    Returns cleaned list with new keys\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for month in data:\n",
    "        cleaned_month = month.copy()\n",
    "        cleaned_month[\"revenue\"] = month[\"revenue\"] if month[\"revenue\"] is not None else default_revenue\n",
    "        cleaned_month[\"profit\"] = cleaned_month[\"revenue\"] - month[\"expenses\"]\n",
    "        cleaned_month[\"has_campaigns\"] = len(month[\"campaigns\"]) > 0\n",
    "        cleaned.append(cleaned_month)\n",
    "    return cleaned\n",
    "\n",
    "# Campaign performance analysis\n",
    "def analyze_campaigns(data):\n",
    "    # get months with campaigns\n",
    "    campaigns_months = [m for m in data if m[\"has_campaigns\"]]\n",
    "    \n",
    "    if not campaigns_months:\n",
    "        return {\n",
    "            \"avg_revenue_per_campaigns\": 0,\n",
    "            \"best_month\": None,\n",
    "            \"campaigns_coverage\": 0\n",
    "        }\n",
    "    # calculate metrics\n",
    "    avg_revenue =  sum(m[\"revenue\"] for m in campaigns_months) / len(campaigns_months)\n",
    "    best_month = max(campaigns_months, key=lambda x: x[\"revenue\"])[\"month\"]\n",
    "    \n",
    "    return {\n",
    "        \"avg_revenue_per_campaign\": avg_revenue,\n",
    "        \"best_month\": best_month,\n",
    "        \"campaign_coverage\": round(len(campaigns_months)/ len(data),2)\n",
    "    }\n",
    "\n",
    "# Product return rate analysis\n",
    "def identify_high_return_products(data, threshold=0.07):\n",
    "    \"\"\"\n",
    "    Find products with high return rate.\n",
    "    Args:\n",
    "        data: List of sales data dictionaries\n",
    "        threshold: Minimum return rate\n",
    "    Returns:\n",
    "        sorted ascending by return rate\n",
    "        list: Products, Month, Return rate\n",
    "    \"\"\"\n",
    "    high_return = []\n",
    "    for month in data:\n",
    "        for product in month[\"top_products\"]:\n",
    "            if product[\"return_rate\"] > threshold:\n",
    "                high_return.append({\n",
    "                    \"product_name\": product[\"product\"],\n",
    "                    \"month\": month[\"month\"],\n",
    "                    \"return_rate\": product[\"return_rate\"],\n",
    "                    \"units\": product[\"units\"]\n",
    "                })\n",
    "    return sorted(high_return, key=lambda x: x[\"return_rate\"], reverse=True)\n",
    "\n",
    "# Monthly performance report\n",
    "def generate_performance_report(data):\n",
    "    cleaned_data = clean_sales_data(data)\n",
    "    campaign_stats = analyze_campaigns(cleaned_data)\n",
    "    high_return = identify_high_return_products(cleaned_data)\n",
    "    \n",
    "    # calculate report  metrics\n",
    "    total_profit = sum(m[\"profit\"] for m in cleaned_data)\n",
    "    best_month = max(cleaned_data, key=lambda x: x[\"profit\"])\n",
    "    worst_return = high_return[0] if high_return else None\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    # Sales Performance Report\n",
    "    ## Financial Summary\n",
    "    - Total Profit: ${total_profit:,.2f}\n",
    "    - Most Profitable Month: {best_month['month']} (${best_month[\"profit\"]:,.2f})\n",
    "    - Average Revenue per Campaign: ${campaign_stats['avg_revenue_per_campaign']:,.2f}\n",
    "    \n",
    "    ## Product Analysis\n",
    "    - Highest Return Product: {worst_return['product_name'] if worst_return else 'N/A'}\n",
    "    ({worst_return['return_rate']*100:.1f}% in {worst_return['month'] if worst_return else ''})\n",
    "    - Campaign Coverage: {campaign_stats.get('campaign_coverage')*100:.1f}% of months\n",
    "    \"\"\"\n",
    "    return report\n",
    "\n",
    "# Predict next month\n",
    "def predict_next_month(data):\n",
    "    # Get last 3 months with revenue data\n",
    "    valid_months = [m for m in data if m[\"revenue\"] is not None][-3:]\n",
    "    \n",
    "    if not valid_months:\n",
    "        return {\"predicted_revenue\": None, \"warning\": \"Insufficient data\"}\n",
    "    \n",
    "    # Simple moving average forecast\n",
    "    avg_revenue = sum(m[\"revenue\"] for m in valid_months) / len(valid_months)\n",
    "    avg_expenses = sum(m[\"expenses\"] for m in valid_months) / len(valid_months)\n",
    "    \n",
    "    return {\n",
    "        \"predicted_revenue\": round(avg_revenue),\n",
    "        \"predicted_profit\": round(avg_revenue - avg_expenses),\n",
    "        \"warning\": \"Potential loss\" if (avg_revenue - avg_expenses) < 0 else None\n",
    "    }\n",
    "    \n",
    "cleaned_data = clean_sales_data(sales_data)\n",
    "print(\"Cleaned Data Sample:\", cleaned_data[0])\n",
    "print(\"\\nCampaign Analysis:\", analyze_campaigns(cleaned_data))\n",
    "print(\"\\nHigh Return Products:\", identify_high_return_products(cleaned_data))\n",
    "print(\"\\nPerformance Report:\")\n",
    "print(generate_performance_report(sales_data))\n",
    "print(\"\\nNext Month Prediction:\", predict_next_month(cleaned_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "8cd0f63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Gamma': '1. Gamma - Total: 18300, Growth: 0.375 üìà üèÜ'}, {'Beta': '2. Beta - Total: 21900, Growth: 0.2 üìà'}, {'Alpha': '3. Alpha - Total: 15300, Growth: 0.6 üìà'}]\n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE: Quarterly Sales Performance\n",
    "\n",
    "def quarterly_report(teams, q1, q2, q3, q4, growth_threshold=0.1):\n",
    "    sorted_data = sorted(zip(teams, q1, q2, q3, q4, q1 + q2 + q3 + q4), key=lambda x: x[0], reverse=True)\n",
    "    top_rank = sorted_data[0][5]\n",
    "    result = []\n",
    "    for rank, (team, q1, q2, q3, q4, total) in enumerate(sorted_data, start=1):\n",
    "        result.append({\n",
    "            team.title(): f\"{rank}. {team.title()} - Total: {q1+q2+q3+q4}, Growth: {(q4-q1)/q1}\" +\n",
    "            (\" üìà\" if ((q4-q1)/q1) > growth_threshold else \"\") +\n",
    "            (\" üèÜ\" if total == top_rank else \"\")\n",
    "        })\n",
    "    return result\n",
    "    \n",
    "teams = [\"alpha\", \"beta\", \"gamma\"]\n",
    "q1_sales = [3000, 5000, 4000]\n",
    "q2_sales = [3500, 5300, 4200]\n",
    "q3_sales = [4000, 5600, 4600]\n",
    "q4_sales = [4800, 6000, 5500]\n",
    "\n",
    "result = quarterly_report(teams, q1_sales, q2_sales, q3_sales, q4_sales)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e933f394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Support': '1. Support from South - Total Annual Revenue: $33,700, Quarterly Average: $8,425.0, Growth: 16.67% üèÜ', 'Sales': '2. Sales from North - Total Annual Revenue: $54,500, Quarterly Average: $13,625.0, Growth: 29.17% ‚úÖ üìà', 'Marketing': '3. Marketing from East - Total Annual Revenue: $40,300, Quarterly Average: $10,075.0, Growth: 15.79%', 'Development': '4. Development from West - Total Annual Revenue: $64,000, Quarterly Average: $16,000.0, Growth: 13.33% ‚úÖ'}\n"
     ]
    }
   ],
   "source": [
    "def departments_performance_report(departments, regions, q1, q2, q3, q4, growth_threshold=20,revenue_goal=50000):\n",
    "    combined = [(department, region, q1s, q2s, q3s, q4s, q1s+q2s+q3s+q4s) \n",
    "                for department, region, q1s, q2s, q3s, q4s in \n",
    "                zip(departments, regions, q1, q2, q3, q4)]\n",
    "    \n",
    "    sorted_data = sorted(combined, key=lambda x: x[0], reverse=True)\n",
    "    top_department = sorted_data [0][6]\n",
    "    result = {}\n",
    "    for rank, (department, region, q1, q2, q3, q4, total_revenue) in enumerate(sorted_data, start=1):\n",
    "        growth = round((q4-q1)/q1 * 100, 2)\n",
    "        avg = round(total_revenue/4, 2)\n",
    "        result[department.title()] = (\n",
    "            f\"{rank}. {department.title()} from {region.title()} - Total Annual Revenue: ${total_revenue:,}, Quarterly Average: ${avg:,}, Growth: {growth}%\" +\n",
    "            (\" ‚úÖ\" if total_revenue > revenue_goal else \"\") +\n",
    "            (\" üìà\" if growth >= growth_threshold else \"\") +\n",
    "            (\" üèÜ\" if total_revenue == top_department else \"\")\n",
    "        )\n",
    "    return result\n",
    "\n",
    "departments = [\"sales\", \"marketing\", \"support\", \"development\"]\n",
    "regions = [\"north\", \"east\", \"south\", \"west\"]\n",
    "\n",
    "q1_revenue = [12000, 9500, 7800, 15000]\n",
    "q2_revenue = [13000, 9800, 8200, 15800]\n",
    "q3_revenue = [14000, 10000, 8600, 16200]\n",
    "q4_revenue = [15500, 11000, 9100, 17000]\n",
    "\n",
    "result = departments_performance_report(departments, regions, q1_revenue, q2_revenue, q3_revenue, q4_revenue)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "28287240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data_quality_issues\": {\n",
      "        \"customer_with_no_purchases\": 1,\n",
      "        \"missing_age_values\": 1,\n",
      "        \"purchases_with_null_category\": 1\n",
      "    },\n",
      "    \"loyalty_tier_analysis\": {\n",
      "        \"Gold\": {\n",
      "            \"avg_purchase_amount\": 162.16,\n",
      "            \"most_popular_category\": \"Electronics\",\n",
      "            \"purchases_per_customer\": 3.0\n",
      "        },\n",
      "        \"Silver\": {\n",
      "            \"avg_purchase_amount\": 97.75,\n",
      "            \"most_popular_category\": \"Clothing\",\n",
      "            \"purchases_per_customer\": 2.0\n",
      "        },\n",
      "        \"Bronze\": {\n",
      "            \"avg_purchase_amount\": 0,\n",
      "            \"most_popular_category\": \"N/A\",\n",
      "            \"purchases_per_customer\": 0.0\n",
      "        }\n",
      "    },\n",
      "    \"age_cohort_analysis\": {\n",
      "        \"20-29\": {\n",
      "            \"avg_total_spend\": 486.48,\n",
      "            \"popular_category\": \"Electronics\",\n",
      "            \"repeat_purchase_rate\": 1.0\n",
      "        },\n",
      "        \"40-49\": {\n",
      "            \"avg_total_spend\": 195.5,\n",
      "            \"popular_category\": \"Clothing\",\n",
      "            \"repeat_purchase_rate\": 1.0\n",
      "        },\n",
      "        \"Unknown\": {\n",
      "            \"avg_total_spend\": 0.0,\n",
      "            \"popular_category\": \"N/A\",\n",
      "            \"repeat_purchase_rate\": 0.0\n",
      "        }\n",
      "    },\n",
      "    \"top_customers\": [\n",
      "        {\n",
      "            \"customer_id\": \"C1001\",\n",
      "            \"total_spend\": 486.48,\n",
      "            \"purchase_count\": 3,\n",
      "            \"electronics_spend\": 396.49\n",
      "        },\n",
      "        {\n",
      "            \"customer_id\": \"C1002\",\n",
      "            \"total_spend\": 195.5,\n",
      "            \"purchase_count\": 2,\n",
      "            \"electronics_spend\": 0\n",
      "        },\n",
      "        {\n",
      "            \"customer_id\": \"C1003\",\n",
      "            \"total_spend\": 0,\n",
      "            \"purchase_count\": 0,\n",
      "            \"electronics_spend\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"churn_risk_customers\": [\n",
      "        {\n",
      "            \"customer_id\": \"C1001\",\n",
      "            \"risk_score\": 1.0,\n",
      "            \"reason\": [\n",
      "                \"Inactive for 750 days\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"customer_id\": \"C1002\",\n",
      "            \"risk_score\": 1.0,\n",
      "            \"reason\": [\n",
      "                \"Inactive for 743 days\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"customer_id\": \"C1003\",\n",
      "            \"risk_score\": 1.0,\n",
      "            \"reasons\": \"No purchase history\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# E-Commerce customer transactions\n",
    "customers = [\n",
    "    {\n",
    "        \"customer_id\": \"C1001\",\n",
    "        \"age\": 28,\n",
    "        \"loyalty_tier\": \"Gold\",\n",
    "        \"purchases\": [\n",
    "            {\"order_id\": \"ORD101\", \"date\": \"2023-01-15\", \"amount\": 150.99, \"category\": \"Electronics\"},\n",
    "            {\"order_id\": \"ORD132\", \"date\": \"2023-03-22\", \"amount\": 89.99, \"category\": \"Home\"},\n",
    "            {\"order_id\": \"ORD156\", \"date\": \"2023-03-29\", \"amount\": 245.50, \"category\": \"Electronics\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"customer_id\": \"C1002\",\n",
    "        \"age\": 42,\n",
    "        \"loyalty_tier\": \"Silver\",\n",
    "        \"purchases\": [\n",
    "            {\"order_id\": \"ORD102\", \"date\": \"2023-01-20\", \"amount\": 75.50, \"category\": \"Clothing\"},\n",
    "            {\"order_id\": \"ORD177\", \"date\": \"2023-04-05\", \"amount\": 120.00, \"category\": None}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"customer_id\": \"C1003\",\n",
    "        \"age\": None,\n",
    "        \"loyalty_tier\": \"Bronze\",\n",
    "        \"purchases\": []  # No purchases\n",
    "    }\n",
    "]\n",
    "\n",
    "# Data Quality Check\n",
    "def validate_customer_data(customers):\n",
    "    \"\"\"\n",
    "    Identifies data quality issues in customer records.\n",
    "    Returns counts of:\n",
    "    - Customers with no purchases\n",
    "    - Missing age values\n",
    "    - Purchases with null categories\n",
    "    \"\"\"\n",
    "    issues =  {\n",
    "        \"customer_with_no_purchases\": 0,\n",
    "        \"missing_age_values\": 0,\n",
    "        \"purchases_with_null_category\": 0\n",
    "    }\n",
    "    \n",
    "    for customer in customers:\n",
    "        if not customer[\"purchases\"]:\n",
    "            issues[\"customer_with_no_purchases\"] += 1\n",
    "        if customer[\"age\"] is None:\n",
    "            issues[\"missing_age_values\"] += 1\n",
    "        for purchase in customer[\"purchases\"]:\n",
    "            if purchase[\"category\"] is None:\n",
    "                issues[\"purchases_with_null_category\"] += 1\n",
    "    return issues\n",
    "# Customer Segmentation\n",
    "from collections import defaultdict\n",
    "\n",
    "def segment_customers(customers):\n",
    "    \"\"\"\n",
    "    Analyzes customers by loyalty tier.\n",
    "    Returns metrics:\n",
    "    - Average purchase amount\n",
    "    - Most popular category\n",
    "    - Purchase frequency (purchases/month)\n",
    "    \"\"\"\n",
    "    segments = defaultdict(lambda: {\n",
    "        \"total_amount\": 0,\n",
    "        \"purchase_count\": 0,\n",
    "        \"category_counts\": defaultdict(int),\n",
    "        \"customer_count\": 0\n",
    "    })\n",
    "    \n",
    "    for customer in customers:\n",
    "        tier = customer[\"loyalty_tier\"]\n",
    "        segments[tier][\"customer_count\"] += 1\n",
    "        \n",
    "        for purchase in customer[\"purchases\"]:\n",
    "            segments[tier][\"total_amount\"] += purchase[\"amount\"]\n",
    "            segments[tier][\"purchase_count\"] += 1\n",
    "            segments[tier][\"category_counts\"][purchase[\"category\"]] += 1\n",
    "        \n",
    "        # calculate final metrics\n",
    "        result = {}\n",
    "        for tier, data in segments.items():\n",
    "            avg_amount = data[\"total_amount\"] / data[\"purchase_count\"] if data[\"purchase_count\"] else 0\n",
    "            popular_category = max(data[\"category_counts\"].items(), key=lambda x: x[1])[0] if data[\"category_counts\"] else \"N/A\"\n",
    "            \n",
    "            result[tier] = {\n",
    "                \"avg_purchase_amount\": round(avg_amount, 2),\n",
    "                \"most_popular_category\": popular_category,\n",
    "                \"purchases_per_customer\": round(data[\"purchase_count\"]/ data[\"customer_count\"], 2)\n",
    "            }\n",
    "    return result\n",
    "# Cohort analysis\n",
    "def analyze_cohorts(customers, age_brackets=[20, 30, 40, 50]):\n",
    "    \"\"\"\n",
    "    Groups customers by age brackets and calculates:\n",
    "    - Average total spend\n",
    "    - Most popular category\n",
    "    - Repeat purchase rate\n",
    "    \"\"\"\n",
    "    cohorts = defaultdict(lambda: {\n",
    "        \"customers\": [],\n",
    "        \"total_spend\": 0,\n",
    "        \"purchase_count\": 0,\n",
    "        \"category_counts\": defaultdict(int),\n",
    "        \"repeat_customers\": 0\n",
    "    })\n",
    "    \n",
    "    for customer in customers:\n",
    "        # Determine age bracket\n",
    "        if customer[\"age\"] is None:\n",
    "            bracket = \"Unknown\"\n",
    "        else:\n",
    "            for i in range(len(age_brackets)-1):\n",
    "                if age_brackets[i] <= customer[\"age\"] < age_brackets[i+1]:\n",
    "                    bracket = f\"{age_brackets[i]}-{age_brackets[i+1]-1}\"\n",
    "                    break\n",
    "            else:\n",
    "                bracket = f\"{age_brackets[-1]}+\"\n",
    "        \n",
    "        # Update cohort metrics\n",
    "        cohorts[bracket][\"customers\"].append(customer[\"customer_id\"])\n",
    "        purchase_count = len(customer[\"purchases\"])\n",
    "        \n",
    "        if purchase_count > 1:\n",
    "            cohorts[bracket][\"repeat_customers\"] += 1\n",
    "        \n",
    "        for purchase in customer[\"purchases\"]:\n",
    "            cohorts[bracket][\"total_spend\"] += purchase[\"amount\"]\n",
    "            cohorts[bracket][\"purchase_count\"] += 1\n",
    "            if purchase[\"category\"]:\n",
    "                cohorts[bracket][\"category_counts\"][purchase[\"category\"]] += 1\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    result = {}\n",
    "    for bracket, data in cohorts.items():\n",
    "        avg_spend = data[\"total_spend\"] / len(data[\"customers\"]) if data[\"customers\"] else 0\n",
    "        popular_category = max(data[\"category_counts\"].items(), key=lambda x: x[1])[0] if data[\"category_counts\"] else \"N/A\"\n",
    "        repeat_rate = data[\"repeat_customers\"] / len(data[\"customers\"]) if data[\"customers\"] else 0\n",
    "        \n",
    "        result[bracket] = {\n",
    "            \"avg_total_spend\": round(avg_spend, 2),\n",
    "            \"popular_category\": popular_category,\n",
    "            \"repeat_purchase_rate\": round(repeat_rate, 2)\n",
    "        }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# High Value Customer Identification\n",
    "def identify_high_value_customers(customers, n=3):\n",
    "    \"\"\"\n",
    "    Identifies top customers by:\n",
    "    1. Total spend\n",
    "    2. Purchase frequency\n",
    "    3. Electronics spend (if applicable)\n",
    "    \"\"\"\n",
    "    ranked_customers = []\n",
    "    for customer in customers:\n",
    "        metrics = {\n",
    "            \"customer_id\": customer[\"customer_id\"],\n",
    "            \"total_spend\": sum(p[\"amount\"] for p in customer[\"purchases\"]),\n",
    "            \"purchase_count\": len(customer[\"purchases\"]),\n",
    "            \"electronics_spend\": sum(\n",
    "                p[\"amount\"] for p in customer[\"purchases\"]\n",
    "                if p[\"category\"] == \"Electronics\"\n",
    "            )\n",
    "        }\n",
    "        ranked_customers.append(metrics)\n",
    "        \n",
    "    ranked_customers.sort(key=lambda x: (-x[\"total_spend\"], -x[\"purchase_count\"], -x[\"electronics_spend\"]))\n",
    "    return ranked_customers[:n]\n",
    "\n",
    "# Advanced: Churn Risk Prediction\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def predict_churn_risk(customers, inactive_days=90):\n",
    "    \"\"\"\n",
    "    Flags customers at risk of churn based on:\n",
    "    - No recent purchases (last x days)\n",
    "    - Declining purchase frequency\n",
    "    \"\"\"\n",
    "    today = datetime.now().date()\n",
    "    cutoff_date = today - timedelta(days=inactive_days)\n",
    "    at_risk = []\n",
    "    \n",
    "    for customer in customers:\n",
    "        if not customer[\"purchases\"]:\n",
    "            at_risk.append({\n",
    "                \"customer_id\": customer[\"customer_id\"],\n",
    "                \"risk_score\": 1.0,\n",
    "                \"reasons\": \"No purchase history\"\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Convert string dates to date objects\n",
    "        try:\n",
    "            purchase_dates = [\n",
    "                datetime.strptime(p[\"date\"], \"%Y-%m-%d\").date()\n",
    "                for p in customer[\"purchases\"]\n",
    "            ]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        last_purchase = max(purchase_dates)\n",
    "        \n",
    "        # Calculate purchase frequency change\n",
    "        purchase_months = sorted({d.replace(day=1) for d in purchase_dates})\n",
    "        freq_change = 0\n",
    "        if len(purchase_months) > 1:\n",
    "            freq_change = (len(purchase_dates) / len(purchase_months)) - 1\n",
    "            \n",
    "        # Risk calculation\n",
    "        risk_score = 0\n",
    "        reasons = []\n",
    "        \n",
    "        if last_purchase < cutoff_date:\n",
    "            inactive_weeks = (today - last_purchase).days // 7\n",
    "            risk_score += min(0.5 + inactive_weeks * 0.1, 1.0)\n",
    "            reasons.append(f\"Inactive for {(today - last_purchase).days} days\")\n",
    "        \n",
    "        if freq_change < -0.3: # Frequency dropped > 30%\n",
    "            risk_score += 0.3\n",
    "            reasons.append(f\"Purchase frequency dropping\")\n",
    "        \n",
    "        if risk_score >= 0.5:\n",
    "            at_risk.append({\n",
    "                \"customer_id\": customer[\"customer_id\"],\n",
    "                \"risk_score\": min(risk_score, 1.0),\n",
    "                \"reason\": reasons\n",
    "            })\n",
    "            \n",
    "    return sorted(at_risk, key=lambda x: -x[\"risk_score\"])\n",
    "\n",
    "# Run all analyses\n",
    "data_issues = validate_customer_data(customers)\n",
    "segmentation = segment_customers(customers)\n",
    "cohorts = analyze_cohorts(customers)\n",
    "high_value = identify_high_value_customers(customers)\n",
    "churn_risk = predict_churn_risk(customers)\n",
    "\n",
    "# Generate comprehensive report\n",
    "import json\n",
    "\n",
    "report = {\n",
    "    \"data_quality_issues\": data_issues,\n",
    "    \"loyalty_tier_analysis\": segmentation,\n",
    "    \"age_cohort_analysis\": cohorts,\n",
    "    \"top_customers\": high_value,\n",
    "    \"churn_risk_customers\": churn_risk\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "98aca307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['50', '120 üíµ', '80', '200 üíµ']\n"
     ]
    }
   ],
   "source": [
    "prices = [50, 120, 80, 200]\n",
    "\n",
    "# Output example:\n",
    "# ['50', '120 üíµ', '80', '200 üíµ']\n",
    "\n",
    "# Try it here:\n",
    "tagged_prices = list(map(lambda price: f\"{price} üíµ\" if price > 80 else f\"{price}\" , prices))\n",
    "\n",
    "print(tagged_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "2d190143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sales': 3800, 'Marketing': 3200, 'Support': 1200}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Sample transactions: (department, amount)\n",
    "transactions = [\n",
    "    (\"Sales\", 2000),\n",
    "    (\"Marketing\", 1500),\n",
    "    (\"Sales\", 1800),\n",
    "    (\"Support\", 1200),\n",
    "    (\"Marketing\", 1700),\n",
    "]\n",
    "\n",
    "# Group by department and sum the totals using defaultdict + lambda\n",
    "summary = defaultdict(lambda: 0)\n",
    "\n",
    "for dept, amount in transactions:\n",
    "    summary[dept] += amount\n",
    "\n",
    "print(dict(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "0f123632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Beta', 18000, 0.03), ('Gamma', 16000, 0.08), ('Alpha', 15000, 0.05)]\n"
     ]
    }
   ],
   "source": [
    "# Data: (name, revenue, growth%)\n",
    "data = [\n",
    "    (\"Alpha\", 15000, 0.05),\n",
    "    (\"Beta\", 18000, 0.03),\n",
    "    (\"Gamma\", 16000, 0.08),\n",
    "]\n",
    "\n",
    "# Sort by revenue descending, then growth ascending\n",
    "sorted_data = sorted(data, key=lambda x: (-x[1], x[2]))\n",
    "\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "1bc5fea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alice', 30, 50000.0]\n"
     ]
    }
   ],
   "source": [
    "columns = [\"name\", \"age\", \"income\"]\n",
    "types = [\"str\", \"int\", \"float\"]\n",
    "\n",
    "# Create a dict of processors using lambda\n",
    "processors = {\n",
    "    \"str\": lambda x: x.strip().title(),\n",
    "    \"int\": lambda x: int(x),\n",
    "    \"float\": lambda x: float(x)\n",
    "}\n",
    "\n",
    "# Sample raw row from CSV\n",
    "raw_row = [\" alice \", \"30\", \"50000.0\"]\n",
    "\n",
    "# Apply processors based on types\n",
    "cleaned = [processors[t](v) for v, t in zip(raw_row, types)]\n",
    "\n",
    "print(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "0efcaf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('USA', 35000000), ('India', 32000000), ('Brazil', 21000000)]\n",
      "[('USA', 350000.0), ('India', 320000.0), ('Brazil', 210000.0), ('France', 70000.0), ('Germany', 65000.0)]\n"
     ]
    }
   ],
   "source": [
    "# Sample data: List of tuples (country, cases)\n",
    "covid_data = [\n",
    "    (\"USA\", 35000000),\n",
    "    (\"India\", 32000000),\n",
    "    (\"Brazil\", 21000000),\n",
    "    (\"France\", 7000000),\n",
    "    (\"Germany\", 6500000)\n",
    "]\n",
    "\n",
    "# 1. Filter countries with > 10M cases\n",
    "high_cases = list(filter(lambda item: item[1] > 10_000_000, covid_data))\n",
    "print(high_cases)  # Output: [('USA', 35000000), ('India', 32000000), ('Brazil', 21000000)]\n",
    "\n",
    "# 2. Convert cases to \"per million\" (assuming population data exists)\n",
    "per_million = list(map(lambda item: (item[0], item[1] / 100), covid_data))  # Simplified\n",
    "print(per_million)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "52b149eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 101, 'total': 917.1}, {'id': 103, 'total': 210}]\n"
     ]
    }
   ],
   "source": [
    "orders = [\n",
    "    {\"id\": 101, \"items\": [{\"name\": \"Laptop\", \"price\": 999}, {\"name\": \"Mouse\", \"price\": 20}], \"status\": \"shipped\"},\n",
    "    {\"id\": 102, \"items\": [{\"name\": \"Keyboard\", \"price\": 50}], \"status\": \"pending\"},\n",
    "    {\"id\": 103, \"items\": [{\"name\": \"Monitor\", \"price\": 200}, {\"name\": \"Cable\", \"price\": 10}], \"status\": \"shipped\"}\n",
    "]\n",
    "# Step 1: Filter shipped orders\n",
    "shipped_orders = filter(lambda order: order[\"status\"] == \"shipped\", orders)\n",
    "\n",
    "# Step 2: Calculate totals and apply discount\n",
    "def process_order(order):\n",
    "    total = sum(item[\"price\"] for item in order[\"items\"])\n",
    "    if total > 500:\n",
    "        total *= 0.9 # 10% discount\n",
    "    return {\"id\": order[\"id\"], \"total\": round(total, 2)}\n",
    "\n",
    "# Step 3: Apply to all shipped orders\n",
    "report = map(process_order, shipped_orders)\n",
    "print(list(report))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14cd55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'user': 'Alice', 'model': 'iPhone 12'}, {'user': 'Alice', 'model': 'MacBook Pro'}], [{'user': 'Bob', 'model': 'iPad Air'}]]\n"
     ]
    }
   ],
   "source": [
    "api_response = [\n",
    "    {\n",
    "        \"user\": \"Alice\",\n",
    "        \"devices\": [\n",
    "            {\"type\": \"phone\", \"model\": \"iPhone 12\"},\n",
    "            {\"type\": \"laptop\", \"model\": \"MacBook Pro\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"user\": \"Bob\",\n",
    "        \"devices\": [\n",
    "            {\"type\": \"tablet\", \"model\": \"iPad Air\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Using list comprehension (cleaner for nested loops)\n",
    "flattened = [\n",
    "    {\"user\": user[\"user\"], \"model\": device[\"model\"]}\n",
    "    for user in api_response\n",
    "    for device in user[\"devices\"]\n",
    "]\n",
    "\n",
    "# using map + lambda (less readable here)\n",
    "flattened = list(map(\n",
    "    lambda user: list(map(lambda device: {\"user\": user[\"user\"], \"model\": device[\"model\"]}, user[\"devices\"])), api_response\n",
    "))\n",
    "\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "40a6c267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'discounted_total': 480.0}, {'id': 2, 'discounted_total': 180.0}, {'id': 3, 'discounted_total': 71.25}]\n"
     ]
    }
   ],
   "source": [
    "users = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"tier\": \"gold\", \"purchases\": [100, 200, 300]},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"tier\": \"silver\", \"purchases\": [50, 150]},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"tier\": \"bronze\", \"purchases\": [75]}\n",
    "]\n",
    "\n",
    "def apply_discount(user):\n",
    "    discount_rates = {\"gold\": 0.2, \"silver\": 0.1, \"bronze\": 0.05}\n",
    "    total = sum(user[\"purchases\"])\n",
    "    discount = total * discount_rates[user[\"tier\"]]\n",
    "    return {\"id\": user[\"id\"], \"discounted_total\": round(total - discount, 2)}\n",
    "\n",
    "discounted_users = map(apply_discount, users)\n",
    "print(list(discounted_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "05f60e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user': 'Alice', 'product': 'Laptop'}, {'user': 'Bob', 'product': 'Mouse'}]\n"
     ]
    }
   ],
   "source": [
    "users = [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}]\n",
    "orders = [{\"user_id\": 1, \"product\": \"Laptop\"}, {\"user_id\": 2, \"product\": \"Mouse\"}]\n",
    "\n",
    "# Using list comprehension\n",
    "merged = [\n",
    "    {\"user\": user[\"name\"], \"product\": next(order[\"product\"] for order in orders if order[\"user_id\"] == user[\"id\"])}\n",
    "    for user in users\n",
    "]\n",
    "\n",
    "# Alternative using map + lambda\n",
    "user_dict = {user[\"id\"]: user[\"name\"] for user in users}\n",
    "merged = map(\n",
    "    lambda order: {\"user\": user_dict[order[\"user_id\"]], \"product\": order[\"product\"]},\n",
    "    orders\n",
    ")\n",
    "\n",
    "print(list(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "c315ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"value\": \"100\"}, {\"value\": \"200\"}, {\"value\": \"N/A\"}]\n",
    "\n",
    "# Goal: convert \"value\" to integers, defaulting to 0 for invalid entries.\n",
    "\n",
    "# Using a lambda with try-except\n",
    "parsed = map(\n",
    "    lambda d: {\"value\": int(d[\"value\"])} if d[\"value\"].isdigit() else {\"value\": 0},\n",
    "    data\n",
    ")\n",
    "\n",
    "# Using a helper function (cleaner)\n",
    "def safe_parse(item):\n",
    "    try:\n",
    "        return {\"value\": int(item[\"value\"])}\n",
    "    except:\n",
    "        return {\"value\": 0}\n",
    "parsed = map(safe_parse, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "98482b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Alice', 'projects': ['Data Pipeline']}, {'name': 'Bob', 'projects': []}]\n"
     ]
    }
   ],
   "source": [
    "# Employees and Project data\n",
    "\n",
    "employees = [\n",
    "    {\"id\": 1, \"name\": \"Alice\", \"skills\": [\"Python\", \"SQL\"], \"years\": 5},\n",
    "    {\"id\": 2, \"name\": \"Bob\", \"skills\": [\"Java\"], \"years\": 3},\n",
    "    {\"id\": 3, \"name\": \"Charlie\", \"skills\": [\"Python\", \"JavaScript\"], \"years\": 1}\n",
    "]\n",
    "projects = [\n",
    "    {\"id\": 1, \"name\": \"Web App\", \"required_skills\": [\"Python\", \"JavaScript\"]},\n",
    "    {\"id\": 2, \"name\": \"Data Pipeline\", \"required_skills\": [\"Python\", \"SQL\"]}\n",
    "]\n",
    "\n",
    "# Goal: Match employees to project they're qualified for (all required skills must match).\n",
    "\n",
    "# Step 1: Filter experienced employees.\n",
    "experienced = filter(lambda e: e[\"years\"] > 2, employees)\n",
    "\n",
    "# Step 2: Match projects\n",
    "def match_projects(employee):\n",
    "    eligible_projects = [\n",
    "        project[\"name\"] for project in projects\n",
    "        if all(skill in employee[\"skills\"] for skill in project[\"required_skills\"])\n",
    "    ]\n",
    "    return {\"name\": employee[\"name\"], \"projects\": eligible_projects}\n",
    "\n",
    "matches = map(match_projects, experienced)\n",
    "print(list(matches))\n",
    "    \n",
    "\n",
    "\n",
    "# Include only employees with >2 years of experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering countries with >10M cases and recovery rate >80%\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 35_000_000, \"deaths\": 600_000, \"recovered\": 28_000_000},\n",
    "    {\"country\": \"India\", \"cases\": 32_000_000, \"deaths\": 400_000, \"recovered\": 30_000_000},\n",
    "    {\"country\": \"Brazil\", \"cases\": 21_000_000, \"deaths\": 500_000, \"recovered\": 19_000_000},\n",
    "    {\"country\": \"France\", \"cases\": 7_000_000, \"deaths\": 100_000, \"recovered\": 6_500_000},\n",
    "    {\"country\": \"Germany\", \"cases\": 6_500_000, \"deaths\": 90_000, \"recovered\": 6_000_000}\n",
    "]\n",
    "\n",
    "# List comprehension\n",
    "high_risk = [country for country in covid_data if country[\"cases\"] > 10000000 and (country[\"recovered\"]/ country[\"cases\"]) > 0.8]\n",
    "\n",
    "# Filter + lambda\n",
    "high_risk = filter(lambda country: country[\"cases\"] > 10000000 and (country[\"recovered\"]/ country[\"cases\"]) > 0.8, covid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "b0f351fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'country': 'USA', 'mortality_rate': 1714.29}, {'country': 'India', 'mortality_rate': 1250.0}, {'country': 'Brazil', 'mortality_rate': 2380.95}, {'country': 'France', 'mortality_rate': 1428.57}, {'country': 'Germany', 'mortality_rate': 1384.62}]\n",
      "[{'country': 'USA', 'mortality_rate': 1714.29}, {'country': 'India', 'mortality_rate': 1250.0}, {'country': 'Brazil', 'mortality_rate': 2380.95}, {'country': 'France', 'mortality_rate': 1428.57}, {'country': 'Germany', 'mortality_rate': 1384.62}]\n"
     ]
    }
   ],
   "source": [
    "# Calcualte mortality rate (deaths per 100K cases)\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 35_000_000, \"deaths\": 600_000, \"recovered\": 28_000_000},\n",
    "    {\"country\": \"India\", \"cases\": 32_000_000, \"deaths\": 400_000, \"recovered\": 30_000_000},\n",
    "    {\"country\": \"Brazil\", \"cases\": 21_000_000, \"deaths\": 500_000, \"recovered\": 19_000_000},\n",
    "    {\"country\": \"France\", \"cases\": 7_000_000, \"deaths\": 100_000, \"recovered\": 6_500_000},\n",
    "    {\"country\": \"Germany\", \"cases\": 6_500_000, \"deaths\": 90_000, \"recovered\": 6_000_000}\n",
    "]\n",
    "\n",
    "# Using comprehension\n",
    "mortality_rates_comp = [{\n",
    "    \"country\": country[\"country\"],\n",
    "    \"mortality_rate\": round((country[\"deaths\"] / country[\"cases\"]) * 100_000, 2)\n",
    "} for country in covid_data\n",
    "]\n",
    "print(mortality_rates_comp)\n",
    "\n",
    "# Using map + lambda\n",
    "mortality_rates_map = map(lambda mortality: {\n",
    "    \"country\": mortality[\"country\"],\n",
    "    \"mortality_rate\": round((mortality[\"deaths\"] / mortality[\"cases\"]) * 100_000, 2)}, covid_data\n",
    "    )\n",
    "print(list(mortality_rates_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "df914f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA', 'Brazil']\n",
      "['USA', 'Brazil']\n"
     ]
    }
   ],
   "source": [
    "# Filter country with mortality rate > 1,500\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 35_000_000, \"deaths\": 600_000, \"recovered\": 28_000_000},\n",
    "    {\"country\": \"India\", \"cases\": 32_000_000, \"deaths\": 400_000, \"recovered\": 30_000_000},\n",
    "    {\"country\": \"Brazil\", \"cases\": 21_000_000, \"deaths\": 500_000, \"recovered\": 19_000_000},\n",
    "    {\"country\": \"France\", \"cases\": 7_000_000, \"deaths\": 100_000, \"recovered\": 6_500_000},\n",
    "    {\"country\": \"Germany\", \"cases\": 6_500_000, \"deaths\": 90_000, \"recovered\": 6_000_000}\n",
    "]\n",
    "# Using comprehension\n",
    "low_risk_comp = [\n",
    "    country[\"country\"] for country in covid_data if ((country[\"deaths\"]/country[\"cases\"]) * 100_000) > 1500\n",
    "]\n",
    "print(low_risk_comp)\n",
    "\n",
    "# Using map + filter + lambda\n",
    "low_risk_filter = map(lambda country: country[\"country\"], filter(lambda mortality: (mortality[\"deaths\"]/ mortality[\"cases\"] * 100_000) > 1500, covid_data))\n",
    "print(list(low_risk_filter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "4c3499da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global recovery rate: 88.18%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the global average recovery rate.\n",
    "covid_data = [\n",
    "    {\"country\": \"USA\", \"cases\": 35_000_000, \"deaths\": 600_000, \"recovered\": 28_000_000},\n",
    "    {\"country\": \"India\", \"cases\": 32_000_000, \"deaths\": 400_000, \"recovered\": 30_000_000},\n",
    "    {\"country\": \"Brazil\", \"cases\": 21_000_000, \"deaths\": 500_000, \"recovered\": 19_000_000},\n",
    "    {\"country\": \"France\", \"cases\": 7_000_000, \"deaths\": 100_000, \"recovered\": 6_500_000},\n",
    "    {\"country\": \"Germany\", \"cases\": 6_500_000, \"deaths\": 90_000, \"recovered\": 6_000_000}\n",
    "]\n",
    "\n",
    "# Using comprehension\n",
    "total_cases = sum(cases[\"cases\"] for cases in covid_data)\n",
    "total_recovered = sum(recover[\"recovered\"] for recover in covid_data)\n",
    "global_recover_comp = round((total_recovered / total_cases) * 100, 2)\n",
    "\n",
    "result = f\"Global recovery rate: {global_recover_comp}%\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a3e13ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 93.75]\n"
     ]
    }
   ],
   "source": [
    "covid_data_missing = [\n",
    "    {\"country\": \"USA\", \"cases\": 35_000_000, \"deaths\": 600_000},\n",
    "    {\"country\": \"India\", \"cases\": 32_000_000, \"deaths\": 400_000, \"recovered\": 30_000_000}\n",
    "]\n",
    "\n",
    "def safe_recovery_rate(country):\n",
    "    if \"recovered\" in country:\n",
    "        return (country[\"recovered\"] / country[\"cases\"] * 100)\n",
    "\n",
    "rates = map(safe_recovery_rate, covid_data_missing)\n",
    "print(list(rates))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
