{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f59b63",
   "metadata": {},
   "source": [
    "# **The \"Digital Eye\" (MNIST)**\n",
    "\n",
    "**The Mission:** Build a brain that can read human handwriting. **The Data**: 70,000 images of handwritten digits (0-9). This is the famous **MNIST** dataset (the \"Hello World\" of Computer Vision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87cd2f",
   "metadata": {},
   "source": [
    "#### Step 1: Load the data\n",
    "We don't need to download a CSV. This dataset is so famous that it comes built-in with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f677c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0413192d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (60000, 28, 28)\n",
      "Test Data Shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "# x_train: The images (28x28 pixels)\n",
    "# y_train: The labels (The number 0-9)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(f\"Training Data Shape: {x_train.shape}\")\n",
    "print(f\"Test Data Shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7a4ab3",
   "metadata": {},
   "source": [
    "#### Step 2: See what the Computer Sees\n",
    "Before we train, we must understand our input. To a computer, an image is just a grid of numbers from 0 (black) to 255 (white)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b242281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Pixel Values (Center of image):\n",
      "[[  1 154 253  90   0]\n",
      " [  0 139 253 190   2]\n",
      " [  0  11 190 253  70]\n",
      " [  0   0  35 241 225]\n",
      " [  0   0   0  81 240]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Pick an image (Let's look at the first one)\n",
    "i = 0\n",
    "image = x_train[i]\n",
    "label = y_train[i]\n",
    "\n",
    "# 2. Visualize it\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 3. Peek at the raw numbers (The \"Matrix\")\n",
    "print(f\"Raw Pixel Values (Center of image):\\n{image[10:15, 10:15]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88f151",
   "metadata": {},
   "source": [
    "#### Step 3: Preprocessing (The \"Normalize\" Trick)\n",
    "Neural Network are like picky eaters. They hate big numbers (0-255). They prefer small numbers between **0 - 1**. If we feed them \"255\", the math explodes and training fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f94a588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Max Pixel Value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(f\"New Max Pixel Value: {x_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4c2d7",
   "metadata": {},
   "source": [
    "#### Step 4: Build the Brain\n",
    "This is the moment of truth. We will build a **Sequential Neural Network**.\n",
    "\n",
    "Think of it like a sandwich:\n",
    "1. **Input Layer (`Flatten`)**: Takes the 2D image (28x28) and squashes it into a long line of 784 pixels (1D).\n",
    "2. **Hidden Layer (`Dense`)**: The *\"Brain Cells\"*. We will add 128 neurons. They will try to find patterns (loops, lines).\n",
    "3. **Output Layer (`Dense`)**: 10 neurons (one for each digit 0-9). The one that lights up the brightest is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6de1025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    # Layer 1: Explicit Input Layer\n",
    "    keras.Input(shape=(28, 28)),\n",
    "\n",
    "    # Layer 2: Flatten 2D images to 1D array\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    # Layer 3: The Hidden Layer (128 Neurons)\n",
    "    # 'relu' is the activation function (it turns negative numbers to 0)\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # Layer 4: The Output Layer (10 Neurons or digits 0-9)\n",
    "    # 'softmax' turns the output into probabilities (e.g., \"90% chance it's a 5\")\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the architecture summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02bce1",
   "metadata": {},
   "source": [
    "#### **Explanation:**\n",
    "\n",
    "1. **The Flatten Layer (`flatten_1`)**\n",
    "* **Output Shape `(None, 784)`:** This is the *\"Unrolling\"* step.\n",
    "    * We started with a square image (28 pixels x 28 pixels).\n",
    "    * The model can't read squares; it needs a straight line of numbers.\n",
    "    * So, 28 x 28 = 784.\n",
    "* **Param # `0`:** This layer has **0** things to learn. It just reshapes the data. It's like unfolding a map-the information is the same, just laid out differently.\n",
    "\n",
    "2. **The Hidden Layer (`dense_2`)**\n",
    "* **Output Shape `(None, 128)`:** We chose to have **128 neurons** (brain cells) in this layer to look for patterns.\n",
    "* **Param # `100,480`: (This is the important part)**\n",
    "    * Every single one fo the 784 pixels connects to every single one of the 128 neurons. That is a massive web of connections!\n",
    "    * **The Math**: 784 inputs x 128 neurons = 100,352 connections.\n",
    "    * **The Bias**: Plus, every neuron gets 1 extra *\"Bias\"* variable (like the y-intercept *b* in *y = mx + b*). So add 128.\n",
    "    * **Total**: 100,352 + 128 - 100,480\n",
    "    * **Meaning**: There are **100,480** **tiny knobs** here that the AI will twist and turn during training to learn what a *\"circle\"* or a *\"straight line\"* looks like.\n",
    "\n",
    "3. **The Output Layer (`dense_3`)**\n",
    "* **Output Shape** `(None, 10)`: The final answer must be one of the 10 digits (0 through 9).\n",
    "* **Param #** `1,290`:\n",
    "    * The 128 neurons from the previous layer connect to these 10 final neurons.\n",
    "    * **The Math**: 128 x 10 = 1,280\n",
    "    * **The Bias**: Add 10 biases\n",
    "    * **Total**: 1,290"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e76faf",
   "metadata": {},
   "source": [
    "> **The Big Picture**\n",
    "> **Total params: 101,770:** Your model has **~100,000 trainable parameters**. Think of it like a radio mixing board with 100,000 sliders. When you run `model.fit()`, the computer frantically moves all 100,000 sliders at once to try and get the music (the prediction) to sound perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc8a6a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb493a0",
   "metadata": {},
   "source": [
    "#### **Step 5: Compile & Train**\n",
    "We have to give the model three instructions before it starts:\n",
    "1. **Optimizer** (`adam`): This is the *\"Teacher.\"* It tells the model how to adjust those 100,000 knobs to reduce errors. `Adam` is the best general-purpose teacher.\n",
    "2. **Loss Function** (`sparse_categorical_crossentropy`): This is the *'Scoreboard\"*. It calculates how wrong the answer was (e.g., *\"You guessed 7, but it was a 2. That's a huge error!\"*)\n",
    "3. **Metrics** (`accuracy`): This is what we care about. *\"Did you get it right? Yes or No?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afaa6efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 986us/step - accuracy: 0.9279 - loss: 0.2571\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994us/step - accuracy: 0.9663 - loss: 0.1142\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 938us/step - accuracy: 0.9768 - loss: 0.0784\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9823 - loss: 0.0589\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step - accuracy: 0.9862 - loss: 0.0457\n"
     ]
    }
   ],
   "source": [
    "# 1. Compile (Configuring the learning process)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 2. Train (The heavy lifting)\n",
    "# x_train, y_train: The study material (Images + Correct Answers)\n",
    "# epochs=5: Go through the entire textbook 5 times\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27532f1a",
   "metadata": {},
   "source": [
    "**98,62% accuracy!**\n",
    "\n",
    "That means the model has effectively memorized the training textbook. It can recognize the digits in the training set almost perfectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b552ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c6ce4",
   "metadata": {},
   "source": [
    "#### **Step 6: The \"Final Exam\" (Evaluation)**\n",
    "But.... does it *actually* understand handwriting, or did it just memorize the specific 60,000 images we showed it?\n",
    "\n",
    "We need to test it on the **10,000 images it has never seen before** (the `x_test` set). This is the moment of truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5168800c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - 1ms/step - accuracy: 0.9763 - loss: 0.0766\n",
      "\n",
      "Test Accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the Test Set (Unseen Data)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a17f4",
   "metadata": {},
   "source": [
    "**97,6% Perfect!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e36fb70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df910c31",
   "metadata": {},
   "source": [
    "#### **Step 7: Let's See it in action**\n",
    "Numbers are boring. Let's see the model actually *read* a picture.\n",
    "\n",
    "We will pick a random image from the test set, show it to you, and then ask the model what it thinks it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69e6a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Scores:\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Pick a random test image\n",
    "import random\n",
    "i = random.randint(0, 10000)\n",
    "img = x_test[i]\n",
    "true_label = y_test[i]\n",
    "\n",
    "# 2. Ask the model to predict\n",
    "# (We have to reshape it to (1, 28, 28) because the model expects a batch of images, not just one)\n",
    "prediction = model.predict(img.reshape(1, 28, 28))\n",
    "predicted_label = np.argmax(prediction) # Get the index of the highest probability\n",
    "\n",
    "# 3. Show the result\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"True: {true_label} | Predicted: {predicted_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 4. Show the confidence scores (Probabilty for each number 0-9)\n",
    "print(f\"Confidence Scores:\\n{prediction.round(2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
